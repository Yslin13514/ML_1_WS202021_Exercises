{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "revised-superintendent",
   "metadata": {},
   "source": [
    "Exercises from Yih-Shiuan Lin for Machine learning 1 (WS2020/21)\n",
    "(the iphynb files can be found on GitHub through the link: \\url{https://github.com/Yslin13514/ML_1_WS202021_Exercises}\n",
    "testess\n",
    "\n",
    "# Exercise 1: Estimation Theory\n",
    "### Maximum likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "scientific-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "####### 1. Maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-underwear",
   "metadata": {},
   "source": [
    "## 1.1 Compare the ML estimates of sample size 50 and 5000.\n",
    "\n",
    "The Python codes below generate 1) 50 samples of 2 feature vectors and 2) 5000 samples then use ML to estimate the mean (μ_50 and μ_5000) and covariance (c_50 and μ_5000). The ML estimates different sample sizes are listed below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "manufactured-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu1 =  [ 2.21552175 -1.95085841] mu2 = [ 1.99578642 -1.99983782]\n",
      "\n",
      "cov1 =  \n",
      "[[0.8270328  0.12395854]\n",
      " [0.12395854 0.19393162]] \n",
      "cov2 = \n",
      "[[0.89587384 0.19446545]\n",
      " [0.19446545 0.29932461]]\n"
     ]
    }
   ],
   "source": [
    "### 1.1. Generate 50/5000 samples of bivariate Gaussian distribution and estimate \n",
    "# the mean and variance using Maximum likelihood method.\n",
    "\n",
    "# resources:\n",
    "# https://xavierbourretsicotte.github.io/MLE_Multivariate_Gaussian.html\n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.multivariate_normal.html\n",
    "# https://www.statlect.com/fundamentals-of-statistics/multivariate-normal-distribution-maximum-likelihood\n",
    "\n",
    "sampleN1 = 50\n",
    "sampleN2 = 5000\n",
    "\n",
    "meanVec = np.array([2, -2])\n",
    "covVec = np.array([[0.9, 0.2], [0.2, 0.3]])\n",
    "\n",
    "# We need to transpose the output so it fits 2 arrays.\n",
    "rng = np.random.default_rng(seed = 45)\n",
    "x1, y1 = rng.multivariate_normal(meanVec, covVec, sampleN1).T\n",
    "x2, y2 = rng.multivariate_normal(meanVec, covVec, sampleN2).T\n",
    "rxy1 = np.array([x1, y1]).T\n",
    "rxy2 = np.array([x2, y2]).T\n",
    "\n",
    "# ML estimates\n",
    "mu1 = np.mean(rxy1, axis = 0)\n",
    "mu2 = np.mean(rxy2, axis = 0)\n",
    "cov1 = (rxy1-mu1).T.dot(rxy1-mu1)/sampleN1\n",
    "cov2 = (rxy2-mu2).T.dot(rxy2-mu2)/sampleN2\n",
    "\n",
    "print(\"mu1 = \", mu1, \"mu2 =\", mu2, sep = ' ', end = '\\n\\n')\n",
    "print(\"cov1 = \", cov1, \"cov2 =\", cov2, sep = ' \\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-implement",
   "metadata": {},
   "source": [
    "Compared to the original Gaussian distribution,\n",
    "the ML estimates using 5000 samples are closer to the original distribution values, suggesting that the larger the sample size, the better the estimation results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-birthday",
   "metadata": {},
   "source": [
    "## 1.2 3 classes, 1000 samples each. \n",
    "Next, I sample 1000 data points from three distributions with different mean and covariance values for 1) training and 2) testing data sets (please refer to the exercise sheet for population parameters). We test whether the ML estimates are different with different covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neural-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2. A small classification task: with 3 classes (k = 3). Training and test\n",
    "# sets both have 1000 samples. Each class has 1/3 samples (so maybe 333, 333, 334)\n",
    "\n",
    "sampleC1N = round(1000/3);\n",
    "sampleC2N = round(1000/3);\n",
    "sampleC3N = 1000 - sampleC1N - sampleC2N\n",
    "\n",
    "meanVecC1 = np.array([0, 0, 0]).T\n",
    "meanVecC2 = np.array([1, 2, 2]).T\n",
    "meanVecC3 = np.array([3, 3, 4]).T\n",
    "\n",
    "diagCovVec = np.array([[0.8, 0, 0],\n",
    "                       [0, 0.8, 0],\n",
    "                       [0, 0, 0.8]]);\n",
    "\n",
    "nonDiagCovVec = np.array([[0.8, 0.2, 0.1],\n",
    "                       [0.2, 0.8, 0.2],\n",
    "                       [0.1, 0.2, 0.8]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-teaching",
   "metadata": {},
   "source": [
    "### 1.2.a ML estimates using diagonal covariance matrix:\n",
    "I create two sample sets (training and testing), use training data to estimate parameters, then classify testing data based on the Euclidean distances between data points to the estimated means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "greatest-absolute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu Class1 (diagnal)= \n",
      "[-0.00346203  0.03527569 -0.08631332] \n",
      "mu Class2 (diagnal)= \n",
      "[0.99794333 1.96724925 1.98079457] \n",
      "mu Class3 (diagnal)= \n",
      "[2.98941535 3.04374008 4.02046729]\n",
      "\n",
      "Common covariance matrix (diagnal)=\n",
      " [[ 0.79663621  0.00261447 -0.01079603]\n",
      " [ 0.00261447  0.8023777   0.01894061]\n",
      " [-0.01079603  0.01894061  0.83022934]]\n"
     ]
    }
   ],
   "source": [
    "## diagonal cov matrix\n",
    "rng = np.random.default_rng(seed = 45)\n",
    "# Create samples\n",
    "\n",
    "xC1tr, yC1tr, zC1tr = rng.multivariate_normal(meanVecC1, diagCovVec, sampleC1N).T\n",
    "xC2tr, yC2tr, zC2tr = rng.multivariate_normal(meanVecC2, diagCovVec, sampleC2N).T\n",
    "xC3tr, yC3tr, zC3tr = rng.multivariate_normal(meanVecC3, diagCovVec, sampleC3N).T\n",
    "\n",
    "xC1te, yC1te, zC1te = rng.multivariate_normal(meanVecC1, diagCovVec, sampleC1N).T\n",
    "xC2te, yC2te, zC2te = rng.multivariate_normal(meanVecC2, diagCovVec, sampleC2N).T\n",
    "xC3te, yC3te, zC3te = rng.multivariate_normal(meanVecC3, diagCovVec, sampleC3N).T\n",
    "\n",
    "\n",
    "rxyzC1tr = np.array([xC1tr, yC1tr, zC1tr]).T;\n",
    "rxyzC2tr = np.array([xC2tr, yC2tr, zC2tr]).T;\n",
    "rxyzC3tr = np.array([xC3tr, yC3tr, zC3tr]).T;\n",
    "\n",
    "rxyzC1te = np.array([xC1te, yC1te, zC1te]).T;\n",
    "rxyzC2te = np.array([xC2te, yC2te, zC2te]).T;\n",
    "rxyzC3te = np.array([xC3te, yC3te, zC3te]).T;\n",
    "\n",
    "muC1tr = np.mean(rxyzC1tr, axis = 0)\n",
    "muC2tr = np.mean(rxyzC2tr, axis = 0)\n",
    "muC3tr = np.mean(rxyzC3tr, axis = 0)\n",
    "\n",
    "covC1tr = (rxyzC1tr-muC1tr).T.dot(rxyzC1tr-muC1tr)/sampleC1N\n",
    "covC2tr = (rxyzC2tr-muC2tr).T.dot(rxyzC2tr-muC2tr)/sampleC2N\n",
    "covC3tr = (rxyzC3tr-muC3tr).T.dot(rxyzC3tr-muC3tr)/sampleC3N\n",
    "\n",
    "comCovtr = np.mean([covC1tr, covC2tr, covC3tr], axis = 0);\n",
    "\n",
    "print(\"mu Class1 (diagnal)=\", muC1tr,\"mu Class2 (diagnal)=\", muC2tr,\n",
    "     \"mu Class3 (diagnal)=\", muC3tr, sep = ' \\n', end = '\\n\\n')\n",
    "print(\"Common covariance matrix (diagnal)=\\n\", comCovtr, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-engagement",
   "metadata": {},
   "source": [
    "Classification process and results (diagonal):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "talented-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification ACC (diagnal)= [0.936]\n"
     ]
    }
   ],
   "source": [
    "# Classification: assigning each data point to one class\n",
    "\n",
    "labelsC1 = np.ones([sampleC1N,1])*1\n",
    "labelsC2 = np.ones([sampleC2N,1])*2\n",
    "labelsC3 = np.ones([sampleC3N,1])*3\n",
    "\n",
    "testAnsC1 = np.zeros([sampleC1N,1])\n",
    "testAnsC2 = np.zeros([sampleC2N,1])\n",
    "testAnsC3 = np.zeros([sampleC3N,1])\n",
    "\n",
    "corrAnsC1 = np.zeros([sampleC1N,1])\n",
    "corrAnsC2 = np.zeros([sampleC2N,1])\n",
    "corrAnsC3 = np.zeros([sampleC3N,1])\n",
    "\n",
    "## Stupid way of doing stuff... but it works, so (shrug)\n",
    "i = 0\n",
    "for xyz1 in rxyzC1tr:\n",
    "    \n",
    "    #print(xyz1)\n",
    "    \n",
    "    distC1 = np.sqrt(np.sum((xyz1-muC1tr)**2))\n",
    "    distC2 = np.sqrt(np.sum((xyz1-muC2tr)**2))\n",
    "    distC3 = np.sqrt(np.sum((xyz1-muC3tr)**2))\n",
    "    \n",
    "    minDist = np.argmin([distC1, distC2, distC3])\n",
    "    \n",
    "    if minDist == 0:\n",
    "        testAnsC1[i] = 1\n",
    "        corrAnsC1[i] = 1\n",
    "    elif minDist == 1:\n",
    "        testAnsC1[i] = 2\n",
    "    else:\n",
    "        testAnsC1[i] = 3\n",
    "    i = i+1\n",
    "\n",
    "j = 0\n",
    "for xyz2 in rxyzC2tr:\n",
    "    \n",
    "    #print(xyz1)\n",
    "    \n",
    "    distC1 = np.sqrt(np.sum((xyz2-muC1tr)**2))\n",
    "    distC2 = np.sqrt(np.sum((xyz2-muC2tr)**2))\n",
    "    distC3 = np.sqrt(np.sum((xyz2-muC3tr)**2))\n",
    "    \n",
    "    minDist = np.argmin([distC1, distC2, distC3])\n",
    "    \n",
    "    if minDist == 0:\n",
    "        testAnsC2[j] = 1\n",
    "    elif minDist == 1:\n",
    "        testAnsC2[j] = 2\n",
    "        corrAnsC2[j] = 1\n",
    "    else:\n",
    "        testAnsC2[j] = 3\n",
    "    j = j+1\n",
    "\n",
    "k = 0\n",
    "for xyz3 in rxyzC3tr:\n",
    "    \n",
    "    #print(xyz1)\n",
    "    \n",
    "    distC1 = np.sqrt(np.sum((xyz3-muC1tr)**2))\n",
    "    distC2 = np.sqrt(np.sum((xyz3-muC2tr)**2))\n",
    "    distC3 = np.sqrt(np.sum((xyz3-muC3tr)**2))\n",
    "    \n",
    "    minDist = np.argmin([distC1, distC2, distC3])\n",
    "    \n",
    "    if minDist == 0:\n",
    "        testAnsC3[k] = 1\n",
    "    elif minDist == 1:\n",
    "        testAnsC3[k] = 2\n",
    "    else:\n",
    "        testAnsC3[k] = 3\n",
    "        corrAnsC3[k] = 1\n",
    "    k = k+1\n",
    "\n",
    "diagACC = sum([sum(corrAnsC1), sum(corrAnsC2), sum(corrAnsC3)])/1000\n",
    "print(\"Classification ACC (diagnal)=\", diagACC, sep = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-knitting",
   "metadata": {},
   "source": [
    "### 1.2.b ML estimates using non-diagonal covariance matrix:\n",
    "Doing the same thing again but with non-diagonal covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "constitutional-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu Class1 (nondiagnal)= \n",
      "[-0.00732669  0.05811927 -0.05399205] \n",
      "mu Class2 (nondiagnal)= \n",
      "[0.97234636 2.0139176  2.01567153] \n",
      "mu Class3 (nondiagnal)= \n",
      "[3.04356894 2.99495709 3.98570626]\n",
      "\n",
      "Common covariance matrix (nondiagnal)=\n",
      " [[0.81665844 0.18022695 0.10726268]\n",
      " [0.18022695 0.79987768 0.19897843]\n",
      " [0.10726268 0.19897843 0.80202791]]\n",
      "\n",
      "Classification ACC (non diagnal)= [0.896]\n"
     ]
    }
   ],
   "source": [
    "## non-diagonal cov matrix\n",
    "rng = np.random.default_rng(seed = 45)\n",
    "\n",
    "xC1trnd, yC1trnd, zC1trnd = rng.multivariate_normal(meanVecC1, nonDiagCovVec, sampleC1N).T\n",
    "xC2trnd, yC2trnd, zC2trnd = rng.multivariate_normal(meanVecC2, nonDiagCovVec, sampleC2N).T\n",
    "xC3trnd, yC3trnd, zC3trnd = rng.multivariate_normal(meanVecC3, nonDiagCovVec, sampleC3N).T\n",
    "\n",
    "xC1tend, yC1tend, zC1tend = rng.multivariate_normal(meanVecC1, nonDiagCovVec, sampleC1N).T\n",
    "xC2tend, yC2tend, zC2tend = rng.multivariate_normal(meanVecC2, nonDiagCovVec, sampleC2N).T\n",
    "xC3tend, yC3tend, zC3tend = rng.multivariate_normal(meanVecC3, nonDiagCovVec, sampleC3N).T\n",
    "\n",
    "\n",
    "rxyzC1trnd = np.array([xC1trnd, yC1trnd, zC1trnd]).T;\n",
    "rxyzC2trnd = np.array([xC2trnd, yC2trnd, zC2trnd]).T;\n",
    "rxyzC3trnd = np.array([xC3trnd, yC3trnd, zC3trnd]).T;\n",
    "\n",
    "rxyzC1tend = np.array([xC1tend, yC1tend, zC1tend]).T;\n",
    "rxyzC2tend = np.array([xC2tend, yC2tend, zC2tend]).T;\n",
    "rxyzC3tend = np.array([xC3tend, yC3tend, zC3tend]).T;\n",
    "\n",
    "muC1trnd = np.mean(rxyzC1trnd, axis = 0)\n",
    "muC2trnd = np.mean(rxyzC2trnd, axis = 0)\n",
    "muC3trnd = np.mean(rxyzC3trnd, axis = 0)\n",
    "\n",
    "covC1trnd = (rxyzC1trnd-muC1trnd).T.dot(rxyzC1trnd-muC1trnd)/sampleC1N\n",
    "covC2trnd = (rxyzC2trnd-muC2trnd).T.dot(rxyzC2trnd-muC2trnd)/sampleC2N\n",
    "covC3trnd = (rxyzC3trnd-muC3trnd).T.dot(rxyzC3trnd-muC3trnd)/sampleC3N\n",
    "\n",
    "nondiagcomCovtr = np.mean([covC1trnd, covC2trnd, covC3trnd], axis = 0);\n",
    "print(\"mu Class1 (nondiagnal)=\", muC1trnd,\"mu Class2 (nondiagnal)=\", muC2trnd,\n",
    "     \"mu Class3 (nondiagnal)=\", muC3trnd, sep = ' \\n', end = '\\n\\n')\n",
    "print(\"Common covariance matrix (nondiagnal)=\\n\", nondiagcomCovtr, sep=' ', end='\\n\\n')\n",
    "\n",
    "# Classification: assigning each data point to one class\n",
    "\n",
    "labelsC1nd = np.ones([sampleC1N,1])*1\n",
    "labelsC2nd = np.ones([sampleC2N,1])*2\n",
    "labelsC3nd = np.ones([sampleC3N,1])*3\n",
    "\n",
    "testAnsC1nd = np.zeros([sampleC1N,1])\n",
    "testAnsC2nd = np.zeros([sampleC2N,1])\n",
    "testAnsC3nd = np.zeros([sampleC3N,1])\n",
    "\n",
    "corrAnsC1nd = np.zeros([sampleC1N,1])\n",
    "corrAnsC2nd = np.zeros([sampleC2N,1])\n",
    "corrAnsC3nd = np.zeros([sampleC3N,1])\n",
    "\n",
    "## Stupid way of doing stuff... but it works, so (shrug)\n",
    "i = 0\n",
    "for xyz1 in rxyzC1trnd:\n",
    "    \n",
    "    #print(xyz1)\n",
    "    \n",
    "    distC1 = np.sqrt(np.sum((xyz1-muC1trnd)**2))\n",
    "    distC2 = np.sqrt(np.sum((xyz1-muC2trnd)**2))\n",
    "    distC3 = np.sqrt(np.sum((xyz1-muC3trnd)**2))\n",
    "    \n",
    "    minDist = np.argmin([distC1, distC2, distC3])\n",
    "    \n",
    "    if minDist == 0:\n",
    "        testAnsC1nd[i] = 1\n",
    "        corrAnsC1nd[i] = 1\n",
    "    elif minDist == 1:\n",
    "        testAnsC1nd[i] = 2\n",
    "    else:\n",
    "        testAnsC1nd[i] = 3\n",
    "    i = i+1\n",
    "\n",
    "j = 0\n",
    "for xyz2 in rxyzC2trnd:\n",
    "    \n",
    "    #print(xyz1)\n",
    "    \n",
    "    distC1 = np.sqrt(np.sum((xyz2-muC1trnd)**2))\n",
    "    distC2 = np.sqrt(np.sum((xyz2-muC2trnd)**2))\n",
    "    distC3 = np.sqrt(np.sum((xyz2-muC3trnd)**2))\n",
    "    \n",
    "    minDist = np.argmin([distC1, distC2, distC3])\n",
    "    \n",
    "    if minDist == 0:\n",
    "        testAnsC2nd[j] = 1\n",
    "    elif minDist == 1:\n",
    "        testAnsC2nd[j] = 2\n",
    "        corrAnsC2nd[j] = 1\n",
    "    else:\n",
    "        testAnsC2nd[j] = 3\n",
    "    j = j+1\n",
    "\n",
    "k = 0\n",
    "for xyz3 in rxyzC3trnd:\n",
    "    \n",
    "    #print(xyz1)\n",
    "    \n",
    "    distC1 = np.sqrt(np.sum((xyz3-muC1trnd)**2))\n",
    "    distC2 = np.sqrt(np.sum((xyz3-muC2trnd)**2))\n",
    "    distC3 = np.sqrt(np.sum((xyz3-muC3trnd)**2))\n",
    "    \n",
    "    minDist = np.argmin([distC1, distC2, distC3])\n",
    "    \n",
    "    if minDist == 0:\n",
    "        testAnsC3nd[k] = 1\n",
    "    elif minDist == 1:\n",
    "        testAnsC3nd[k] = 2\n",
    "    else:\n",
    "        testAnsC3nd[k] = 3\n",
    "        corrAnsC3nd[k] = 1\n",
    "    k = k+1\n",
    "\n",
    "nondiagACC = sum([sum(corrAnsC1nd), sum(corrAnsC2nd), sum(corrAnsC3nd)])/1000\n",
    "print(\"Classification ACC (non diagnal)=\", nondiagACC, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-equivalent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
